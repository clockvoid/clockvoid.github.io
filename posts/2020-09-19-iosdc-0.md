---
title: iOSDC 2020 前夜祭
github-link: posts/2020-09-19-iosdc-0.md
summary: 2020年のiOSDC第0日目で気になったセッションや初めて知ったことのまとめです
---

# 前夜祭説明会
iOSDCの配信はニコニコ生放送を使ってやるとのこと．

ドワンゴのオフィスを借りてやっているとのこと．

グリーンバックでリアルタイムに映像を合成している模様．すごい．

## コミュニケーションを大切にしている
- 今年もやっていきましょう．
- Twitter: ハッシュタグ
- Discord: 発生可能パブリックビューイングチャンネルが有る．ここでしゃべることが可能
  - 雑談するチャンネルとかもある（ワークするかわからないけどやってみて）
- ニコ生コメントもやってね

## ハッシュタグ
- 全体
  - #iosdc
- トラックごと
  - #iosdc #a
- Discord
  - #iosdc #vc

## イベント
- Ask the Speaker
  - 今年はDiscordでやる
  - 「面白かったです」だけでも良いし，スライドもう一度見せてください，でもOK
- Feedback
  - シリアルコードの書いてあったメールのURLから送れる
  - コメントなしでもOK．「いいね」だけでもOK
- ツイート企画
  - ヒミツのキーワードが30個くらいある．Tweetでたまたま含まれていたら抽選に参加できる
  - 最終日のお昼に一つづつキーワードを開示

## Day 1
- 10:00からオープニング・セッション
- スポンサー紹介や企画紹介など，頑張ったので是非参加してとのこと
  - 後でYouTubeにも投稿されるが，喋りは含まれない
- おっかけ再生もできる

# SourceKit-LSPをブラウザでコードを読むために活用する
一瞬音が聞こえないトラブルが有りましたが，なんとか復旧

ブラウザでもXcodeを使っているようにコードジャンプとかができるようになる

すでにかつみさんがSafariとChromeのブラウザ拡張を[公開している](https://chrome.google.com/webstore/detail/sourcekit-for-chrome/ndfileljkldjnflefdckeiaedelndafe )．

レポジトリは[ここ](https://github.com/kishikawakatsumi/SourceKitForSafari )

→このブラウザ拡張はGitHubのコードビューワで使用可能

GitHub Code Navigationがあるので，JavaとかJavaScriptiならブラウザ拡張はなくても同じことができる．（Swift向けにはないので，作った）

SourceKit-LSPとは，Appleがオープンソースで開発している，SwiftとObjective-C向けのLSP．

## SourceKit-LSPを使ってみる
Xcode 11.4からSourceKit-LSPが標準でついてくるので，Xcodeをインストールするだけで入手可能

あとは自分が使っているLanguage Clientから使えば良い（？）

発表ではSouceKit-LSPのVSCode拡張をビルドしてインストールしてた．これをやるとSouceKit-LSPの設定項目がVSCodeに現れるらしい．ここで実行用バイナリのパスを設定するとのことだが，おそらくこれはLanguage Clientとしての機能を持っているんだと思う．

標準設定ではmacOS向けの設定になっていて，UIKitとかが使えない．そのため，設定でiOSのプロジェクトとしてビルドするようにオプションを設定し直す必要がある．

## SouceKit-LSPと通信するときの仕組みを見る
JSON-RPCとか言うものを使用してプロセス間通信する

関数の呼び出し方と返り値をJSONで表現するプロトコル．

headerでJSONの長さを格納する必要がある．→受け取り側は毎回サイズを計算しなくてはならない．

レスポンスは一度に帰ってこず，分割して帰ってくることもある．

ただし，基本的にはライブラリがあるので，普通はこういう計算はしなくてもOK

VSCodeでログをVerboseにするとログが全部出てくるので，メッセージの形とかがわかるようになる

![ライフサイクル](https://i.imgur.com/d05yOzim.png )

## 自分で書いたプログラムで通信する
LSPは通信に関する仕様は規定されていない→現状，殆どのLSPは標準入出力を使用している模様

パイプでSourceKit-LSPのプロセスからパイプで自分で作ったプロセスに入力させてみたらいい感じに通信できた

→ただし，サンドボックスをオフにしないと通信できなかった（解決はしない）

SourceKit-LSPには，クライアントのための仕組みも含まれており，`LanguageServerProtocol`と`LanguageServerProtocolJSONRPC`というのが含まれており，リクエストを作成，レスポンスをデコードするのが簡単かつ型安全になる．

## Safari・ChromeのExtensionと連携する
Safari Extensionはページがロードされたことなどをトリガーに読み込まれる

ブラウザ拡張では表示しているWebページにJavaScriptをインジェクトできる

Safari ExtensionではサンドボックはONでなくてはならない→ExtensionはサンドボックをONにして，XPCサービスを経由してサンドボックOFFのSourceKit-LSPを起動する

※サンドボックをOFFにしたバイナリを同梱しているので，App Storeで配布することはできない

ChromeではNative Messagingを代わりに使用する

## iPadでSourceKit-LSPを使用する（！？）
今の所，iOSでは動かない（SourceKit-LSPが動かないので）

SourceKit-LSPをLinuxサーバにデプロイし，iOSとやり取りしてiPadのWebViewからも同じ機能を提供できるようにすることを実験しているとのこと．

これは楽しみ．

# オープンソースAltSwiftUIの発表
SwiftUIはiOS13からしか対応しておらず，この最低バージョンは今後も上がる可能性があり，そのたびに下位OSを切らなくてはならなくなる．

→そこで，SwiftUIと同等の機能を持ったAltSwiftUIを作って見た．

[GitHub](https://github.com/rakutentech/AltSwiftUI )

## AltSwiftUI
基本的なコンポーネントには対応している．

Stateとかも対応している．

プレビューとかにも対応してる

ObservableObjectとかによる双方向データバインディングにも対応してる（`@StateObject`でView側には書く必要がある）

`@State`は`@Binding`で書く

`@Environment`とかにも対応している

Navigationもできる

## 使い方
```swift
struct RamenCell: View {
 
 @StateObject var model = Model()

 var body: View {
   HStack {
     Text()
       .font()

     Button() {
     }.frame()
     .cornerRadius()
     .background()
     // ...（この辺にも対応してる）
    ...
   }
 }
}
```

みたいな感じで普通に書けるっぽい．

これがiOS 11で動くとのこと（全然仕組みとかはわからない（おそらくUIKitを裏で頑張って構築してるっぽい））

```swift
view.transition(.opacity)
```

と書くと，フェードイン・アウトさせることも可能

```swift
Image("icon")
  .scaleEffect()
  .geometryListener()
```

とかやるとスクロールに合わせて画像の大きさとかを変えられる．
（`geometryListener`とかはSwiftUIには存在しないAltSwiftUIの独自機能）

複数行テキストを操作するときはUIKitと同じことを考慮する必要がある．

# 今日からわかるAVAudioEngineのすべて
途中から参加したので初めの方は聞けなかった

## 基本的な使い方
1. AVAudioSessionをアクティブにする
  - このとき，`setPrefferedIOBufferSize()`とかでバッファサイズを変えられる
2. AVAudioEngineと各Nodeの設定をする
  - このとき，`attach`をする必要がある．
3. 作ったNodeを`connect`（つなぎ合わせ）をする必要がある
  - `engine.connect`をいくつかやって，`engine.start()`すると，いくつかのエフェクトとかをつけたものを流すことが可能

## 任意の音声ファイルを再生する
`AVAudioPlayerNode`を使う．これを使うと自分の声にBGMとかを重ねられる

1. `AVAudioFile`を作成する．
  - iOSにはCAFとか言う拡張子がる．中身はAACとかOpas（？）だったりするらしい
2. `player.scheduleFile()`に`AVAudioFile`を投げると音が流れる．

## ファイルに書き出す
各Nodeで`installTap`とか言うのを使うとノードの出力を監視することが可能

→これを使ってAVAudioFileに書き込むことが可能

## 音声を出力しないようにする
配信者のスピーカーから音声を出力しないようにしたい！

MixierNodeを2つ使う．

```swift
let outputMixier = MixierNode()
let muteMixier = MixierNode()
```

こんなことをして`muteMixier`の音をミュートにしてこちらを端末には流し，`outputMixier`の音をライブラリに流して配信する

## RMSを取得する
音圧を取りたい場合に使う．`installTap`から取得可能

## WORLDでボイスチェンジャーを実装する
WorldAppleという例があり，そこでちゃんと実装されている

iOSではfloat32だが，WORLDからはfloat64が来るので変換する必要がある

# J2ObjCを使ってJava資源をiOS開発で使用してみた
SocialHubというSNSクライアントを作る上で，iOSとAndroidで共有のロジックを入れたかったため，Java資産をiOSで使用できるようにするものを使用したかった．

## 検討した技術
- Kotin MPP
  - まだ知見があまりない
  - Javaのライブラリが全部使えなくなる
- Xamarinの中の.NETで書いたものを様々な環境で使えるようにするやつ
  - ジェネリクスが使えないという致命的な問題があるため，断念
- J2ObjC
  - Javaのライブラリがすべて使える
  - 一応Javaで書いているので将来的にKotlin MPPへの乗り換えも考えられる

## J2ObjCについて
2012年にGoogleが発表（古い）

Javaで書いたコードをObjective-Cにトランスパイルするもの．
Javaの標準ライブラリとかもObjectiv-Cにできるので，Javaの資産をすべて仕様可能．

アノテーションを使用して弱参照とかNullabilityの調整とかもできる

## ビルドツール
対応しているツールはかなり多い
- make
- maven
- gradle

この内，一番いい感じにしてくれるのがGradleだったのでGradleを使用した

ただし，Gradleのプラグインは現状メンテされておらず，色々変えないと動かなかった

- Gradleのバージョンを2→4に上げた．
- コンパイルするファイルが多すぎてコンパイラの引数が多すぎてコマンドの文字数オーバーでコンパイルができない
  - リンカを変えて文字数制限を打破

## その他問題点
- JavaのClassの動的読み込み時に読み込むClassがビルドできていなくて落ちる
  - →先回りしてビルドするようにした
- ビルドにすごく時間がかかる
  - MacBook Proでやると30分くらいかかり，バッテリは半分持っていかれる
  - TravisCIを使ってみたが，リソースが貧弱でリミットの50分近くかかる
  - GitHub Actionsを使用することで時間が20分くらいに減り，いい感じになった

## まとめ
- いくつか欠点はあるが，パフォーマンスの問題はなく，iOS版のアプリの大きさも70MBほどと問題無い程度に収まった．
  - UIの作り込みの方に力を入れることができた
- SocialHubのライブラリ部分は[GitHub](https://github.com/uakihir0/SocialHub )で公開されている．
- J2ObjC-gradle（Gradleプラグイン）もフォークしたものが[GitHub](https://github.com/uakihir0/j2objc-gradle )に上がっている

